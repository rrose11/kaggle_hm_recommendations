{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranker Model\n",
    "\n",
    "Read in the datasets created in the previous notebook, run an Optuna experiment to find the best possible hyperparameters, and train the final LightGB Ranker model to generate our final prediction for the Kaggle leaderboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV,GroupKFold,RandomizedSearchCV\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import optuna\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data + fix data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ''\n",
    "\n",
    "# Read in articles data\n",
    "df_art = pd.read_csv('../Data/articles/articles'+sample+'.csv')\n",
    "df_cust = pd.read_csv('../Data/customers/customers'+sample+'.csv')\n",
    "df_trans = pd.read_csv('../Data/transactions_train/transactions_train'+sample+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix format of article IDs\n",
    "df_art['article_id'] = df_art['article_id'].astype(str).str.zfill(10)\n",
    "df_art['detail_desc'] = df_art['detail_desc'].astype(str)\n",
    "df_trans['article_id'] = df_trans['article_id'].astype(str).str.zfill(10)\n",
    "\n",
    "# Fix datetime type\n",
    "df_trans['t_dat'] = pd.to_datetime(df_trans['t_dat'])\n",
    "\n",
    "# Build df_cust age brackets\n",
    "df_cust['Age_Bracket'] = pd.cut(df_cust['age'],[1,19,29,39,49,59,200],labels=[1,2,3,4,5,6]).fillna(2)\n",
    "\n",
    "# Update the color column for df_art\n",
    "df_art['color'] = np.where(df_art['perceived_colour_master_name'].isin(['Blue','Turquoise','Bluish Green']),'Blue',\\\n",
    "                  np.where(df_art['perceived_colour_master_name'].isin(['Green','Yellowish Green','Khaki green']),'Green',\\\n",
    "                  np.where(df_art['perceived_colour_master_name'].isin(['Brown','Beige','Mole']),'Brown',\\\n",
    "                  np.where(df_art['perceived_colour_master_name'].isin(['Grey','Metal']),'Grey',\\\n",
    "                           df_art['perceived_colour_master_name']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training dataset by removing the last 7 days of data\n",
    "\n",
    "test_start_date = '2020-09-09'\n",
    "test_end_date = '2020-09-15'\n",
    "\n",
    "df_trans_train = df_trans.loc[df_trans['t_dat'] < test_start_date,:].copy()\n",
    "df_trans_test = df_trans.loc[(df_trans['t_dat'] >= test_start_date)&(df_trans['t_dat'] <= test_end_date),:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in dataframe in submission format, returns MAP@12\n",
    "def calculate_precision(df_temp):\n",
    "    df = df_temp.copy()\n",
    "    df[list(range(1,13))] = pd.DataFrame(df.prediction.str.split(' ').tolist(),index=df.index)\n",
    "    del df['prediction']\n",
    "    df2 = pd.melt(df,id_vars = ['customer_id'])\n",
    "    df2.columns = ['customer_id','ranking','article_id']\n",
    "    \n",
    "    df_combined = pd.merge(df2,df_trans_test[['customer_id','article_id']].drop_duplicates(),how='inner')\n",
    "    df_combined['CumCount'] = df_combined.sort_values(['customer_id','ranking']).groupby('customer_id').cumcount() + 1\n",
    "    df_combined['Precision'] = df_combined['CumCount'] / df_combined['ranking']\n",
    "    return df_combined['Precision'].sum()/(df_trans_test['customer_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_sample = ''\n",
    "filename = 'Full'\n",
    "\n",
    "# IDENTIFY TEST SET IN FILES INDEX\n",
    "test_set_ind = 15\n",
    "\n",
    "files = [\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0610_0616_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0617_0623_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0624_0630_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0701_0707_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0708_0714_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0715_0721_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0722_0728_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0729_0804_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0805_0811_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0812_0818_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0819_0825_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0826_0901_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0902_0908_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0909_0915_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_0916_0922_yes.feather',\\\n",
    "         '../Datasets/Full'+pct_sample+'/Repurchase_FULL_yes.feather'\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Datasets/Full_Test/Repurchase_0819_0825_yes.feather\n",
      "../Datasets/Full_Test/Repurchase_0826_0901_yes.feather\n",
      "../Datasets/Full_Test/Repurchase_0902_0908_yes.feather\n",
      "1936439\n"
     ]
    }
   ],
   "source": [
    "# COMBINE ALL TRAINING SETS\n",
    "\n",
    "df_train_set = pd.DataFrame()\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    if i == test_set_ind:\n",
    "        break\n",
    "    print(f)\n",
    "    df_temp = pd.read_feather(f)\n",
    "    df_temp['Key'] = df_temp['customer_id'].str[:20]+'_'+str(i)\n",
    "    df_yeses = df_temp.loc[df_temp['Response'] == 1,'customer_id'].unique()\n",
    "    df_train_set = pd.concat([df_train_set,df_temp.loc[df_temp['customer_id'].isin(df_yeses)]])\n",
    "    del df_temp\n",
    "    del df_yeses\n",
    "\n",
    "df_train_set = df_train_set.reset_index(drop=True)\n",
    "print(len(df_train_set))\n",
    "\n",
    "del df_train_set['article_id']\n",
    "del df_train_set['customer_id']\n",
    "if 'HasCustomerBoughtArticle' in df_train_set.columns:\n",
    "    del df_train_set['HasCustomerBoughtArticle']\n",
    "    \n",
    "df_train_set['SaleChangeLastWeek'] = df_train_set['PriceLastWeekVsMean'] / df_train_set['Price2WeeksAgoVsMean']\n",
    "df_train_set['SaleChangeLastMonth'] = df_train_set['PriceLastWeekVsMean'] / df_train_set['PriceLastMonthVsMean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTUNA\n",
    "\n",
    "Determine the best possible hyperparameters for the LightGB model\n",
    "\n",
    "Score the experiments against the **MAP@12 of the result**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modeling dataset, pull yes instances + 10K no instances\n",
    "df = df_train_set.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x)).sort_values(by=['Key'])\n",
    "del df_train_set\n",
    "\n",
    "qids_train = df.groupby('Key')['Key'].count().to_numpy()\n",
    "X_train = df.drop(['Response','Key'], axis=1)\n",
    "y_train = df[\"Response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ IN TEST SET\n",
    "df_test_set = pd.read_feather(files[test_set_ind])\n",
    "print(files[test_set_ind],len(df_test_set))\n",
    "\n",
    "if 'HasCustomerBoughtArticle' in df_test_set.columns:\n",
    "        del df_test_set['HasCustomerBoughtArticle']\n",
    "\n",
    "purchase_cust = df_test_set.loc[df_test_set['Response']==1,'customer_id']\n",
    "\n",
    "# Create test output\n",
    "testDF = df_test_set.loc[df_test_set['customer_id'].isin(purchase_cust),['customer_id','article_id','Response']].copy()\n",
    "\n",
    "# Create test data (only need response variable if create_test flag is set to true)\n",
    "df_testX = df_test_set.loc[df_test_set['customer_id'].isin(purchase_cust),\\\n",
    "        [i for i in df_test_set.columns if i not in ['Response','customer_id','article_id','t_dat']]].copy()\n",
    "del df_test_set\n",
    "del purchase_cust\n",
    "\n",
    "print(len(testDF))\n",
    "\n",
    "n_custs_w_purchase = testDF.loc[testDF['Response']==1,'customer_id'].nunique()\n",
    "print(n_custs_w_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global testDF\n",
    "    param = {\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', .0001, 100),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', .0001, 100),\n",
    "        'min_split_gain': trial.suggest_loguniform('min_split_gain',1e-4,15),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.8,0.9,1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.8,0.9,1.0]),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .01,.4),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',300,800,step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 500),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 60)\n",
    "    }\n",
    "    \n",
    "    lgbr = lgbm.LGBMRanker(boosting_type='goss',random_state=123,metric='map',**param)\n",
    "\n",
    "    lgbr.fit(X_train,y_train,group=qids_train,callbacks=[lgbm.log_evaluation(period=0)])\n",
    "\n",
    "    # Calculate the MAP@12 of the result\n",
    "    testDF['Pred'] = lgbr.predict(df_testX)\n",
    "    testDF['Rank'] = testDF.groupby('customer_id')['Pred'].rank('first',ascending=False)\n",
    "    testScore = testDF.loc[(testDF['Rank'] <= 12)&(testDF['Response']==1)].sort_values(by=['customer_id','Rank'])\n",
    "\n",
    "    testScore['CumCount'] = testScore.sort_values(['customer_id','Rank']).groupby('customer_id').cumcount() + 1\n",
    "    testScore['Precision'] = testScore['CumCount'] / testScore['Rank']\n",
    "    return testScore['Precision'].sum()/n_custs_w_purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = study.trials\n",
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Ranker\n",
    "\n",
    "Build a final LGBMRanker model against the output hyperparameters of the Optuna experiment!\n",
    "\n",
    "- Train 10 models, and average the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0:00:00\n",
      "1 0:01:07.505210\n",
      "2 0:02:15.632743\n",
      "3 0:03:25.566043\n",
      "4 0:04:33.642781\n",
      "5 0:05:42.010696\n",
      "6 0:06:59.000730\n",
      "7 0:08:07.893584\n",
      "8 0:09:16.573622\n",
      "9 0:10:26.566826\n"
     ]
    }
   ],
   "source": [
    "## SET UP THE DATASET\n",
    "\n",
    "# Create modeling dataset, pull yes instances + 10K no instances\n",
    "df = df_train_set.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x)).sort_values(by=['Key'])\n",
    "del df_train_set\n",
    "\n",
    "qids_train = df.groupby('Key')['Key'].count().to_numpy()\n",
    "X_train = df.drop(['Response','Key'], axis=1)\n",
    "y_train = df[\"Response\"]\n",
    "\n",
    "# 5% Data\n",
    "# params = {'reg_lambda': 4.222088769929572, 'reg_alpha': 1.3345544183135867, 'min_split_gain': 0.005242797796112651,\\\n",
    "#           'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.039022659722173045, 'n_estimators': 420,\\\n",
    "#           'max_depth': 4, 'min_child_weight': 316, 'num_leaves': 8}\n",
    "\n",
    "# Full Data\n",
    "params = {'reg_lambda': 35.71755773124274, 'reg_alpha': 0.2518721758654253, 'min_split_gain': 0.00011623209704661628,\\\n",
    "          'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.11023533624106883, 'n_estimators': 700,\\\n",
    "          'max_depth': 5, 'min_child_weight': 450, 'num_leaves': 15}\n",
    "\n",
    "# Full test\n",
    "models = []\n",
    "strt = dt.datetime.now()\n",
    "for rs in range(10):\n",
    "    print(rs,dt.datetime.now()-strt)\n",
    "    lgbr = lgbm.LGBMRanker(boosting_type='goss',random_state=123,metric='map',**params)\n",
    "\n",
    "    lgbr.fit(X_train,y_train,\n",
    "            group=qids_train,\n",
    "            callbacks=[lgbm.log_evaluation(period=0)])\n",
    "    \n",
    "    models.append(lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IsRepeat': 7,\n",
       " 'IsLast30Days': 4,\n",
       " 'IsAssociation': 72,\n",
       " 'IsGenPred': 46,\n",
       " 'IsNeighbor': 47,\n",
       " 'NumListsAppeared': 69,\n",
       " 'UniqueDaysCustBoughtArt': 45,\n",
       " 'DaysSinceCustLastPurchasedArt': 370,\n",
       " 'age': 121,\n",
       " 'WeeksFromPeak': 128,\n",
       " 'PriceLastWeekVsMean': 232,\n",
       " 'CustomerPropensityToBuySales': 236,\n",
       " 'ArtCustSalePropensity': 100,\n",
       " 'Price2WeeksAgoVsMean': 174,\n",
       " 'PriceLastMonthVsMean': 129,\n",
       " 'GenderPropensity': 229,\n",
       " 'AgePropensity': 241,\n",
       " 'PctTimeFrame': 255,\n",
       " 'garment_group_noPopularityLastWeek': 233,\n",
       " 'product_type_noPopularityLastWeek': 239,\n",
       " 'section_noPopularityLastWeek': 263,\n",
       " 'RepurchaseFactor_cust': 276,\n",
       " 'RepurchaseFactor_art': 378,\n",
       " 'MedianAge': 180,\n",
       " 'YearsFromMedianAge': 308,\n",
       " 'DaysSinceFirstSold': 251,\n",
       " 'DaysSinceLastSold': 32,\n",
       " 'AverageSalePriceOverall': 222,\n",
       " 'AverageSalePriceLastWk': 227,\n",
       " 'PriceOverallStdFromCustomerMean': 179,\n",
       " 'PriceLastWkStdFromCustomerMean': 247,\n",
       " 'PctOfPeakWeeklySales': 0,\n",
       " 'PurchaseRatePerWeek': 232,\n",
       " 'PurchaseRateLastWeek': 227,\n",
       " 'LastWeekPopularity': 245,\n",
       " 'PurchaseRateLastMonth': 321,\n",
       " 'LastMonthPopularity': 189,\n",
       " 'SalesChannelSimilarity': 448,\n",
       " 'popularity_quotient': 229,\n",
       " 'product_group_name_similarity': 144,\n",
       " 'perceived_colour_value_name_similarity': 158,\n",
       " 'color_similarity': 148,\n",
       " 'index_code_similarity': 132,\n",
       " 'garment_group_name_similarity': 156,\n",
       " 'overall_metadata_similarity': 132,\n",
       " 'SaleChangeLastWeek': 184,\n",
       " 'SaleChangeLastMonth': 219}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the feature importances of the model\n",
    "{X_train.columns[i]:lgbr.feature_importances_[i] for i in range(len(X_train.columns))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(file):\n",
    "    #READ IN TEST SET\n",
    "    df_test_set = pd.read_feather(file)\n",
    "    print(file,len(df_test_set))\n",
    "    if 'HasCustomerBoughtArticle' in df_test_set.columns:\n",
    "        del df_test_set['HasCustomerBoughtArticle']\n",
    "        \n",
    "    df_test_set['SaleChangeLastWeek'] = df_test_set['PriceLastWeekVsMean'] / df_test_set['Price2WeeksAgoVsMean']\n",
    "    df_test_set['SaleChangeLastMonth'] = df_test_set['PriceLastWeekVsMean'] / df_test_set['PriceLastMonthVsMean']\n",
    "\n",
    "    # Create test output\n",
    "    testDF = df_test_set[['customer_id','article_id']].copy()\n",
    "\n",
    "    # Create test dataset for LGBMRanker model\n",
    "    df_testX = df_test_set[[i for i in df_test_set.columns if i not in ['Response','customer_id','article_id','t_dat']]].copy()\n",
    "    del df_test_set\n",
    "\n",
    "    strt = dt.datetime.now()\n",
    "\n",
    "    print('Start Predict')\n",
    "    testDF['predict_score'] = lgbr.predict(df_testX)\n",
    "    print('Done',dt.datetime.now()-strt)\n",
    "    del df_testX\n",
    "\n",
    "    # Rank the candidates for each customer\n",
    "    testDF['rank'] = testDF.groupby('customer_id')['predict_score'].rank('first',ascending=False)\n",
    "    \n",
    "    # Filter model predictions down to top N for each person, and must be above threshold\n",
    "    N = 12\n",
    "\n",
    "    df_ans = testDF.loc[(testDF['rank'] <= N),['customer_id','article_id','predict_score','rank']].copy()\n",
    "    del testDF\n",
    "    return df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Datasets/Full_Test/Repurchase_0909_0915_yes.feather 627460\n",
      "Start Predict\n",
      "Done 0:00:04.911810\n"
     ]
    }
   ],
   "source": [
    "df_valid_set = predict_on_test(files[test_set_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the outputs to match final submission template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_outputs(df_vs):\n",
    "    N = 12\n",
    "    # Pivot the results, and concatenate together into the final format\n",
    "    df_pivoted = pd.pivot(df_vs,index='customer_id',columns='rank',values='article_id').fillna('')\n",
    "    df_pivoted.columns = list(range(1,N+1))\n",
    "    df_pivoted['pred_model_list'] = df_pivoted[list(range(1,N+1))].apply(\\\n",
    "                                    lambda row: ' '.join(row.values.astype(str)), axis=1).str.strip(' ')\n",
    "    df_pivoted = df_pivoted[['pred_model_list']].copy().reset_index()\n",
    "    \n",
    "    \n",
    "    # Join to the full list of customers and identify how many predictions are remaining for each\n",
    "    df_final = df_pivoted[['customer_id']].drop_duplicates().copy()\n",
    "    df_final = pd.merge(df_final,df_pivoted,how='left',on='customer_id')\n",
    "    df_final['pred_model_list'] = df_final['pred_model_list'].fillna('').str.split(' ')\n",
    "    \n",
    "    df_final['prediction'] = df_final['pred_model_list'].apply(lambda x:' '.join(x))\n",
    "    del df_final['pred_model_list']\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000757967448a6cb83efb3ea7a3fb9d418ac7adf2379d...</td>\n",
       "      <td>0706016001 0448509014 0715624001 0673677002 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fb6e772c5d0023892065e659963da90b1866035558e...</td>\n",
       "      <td>0831684001 0740519002 0158340001 0915529003 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00125440be6cd148c3599b9c5a2d55f5838c1b0257d356...</td>\n",
       "      <td>0892279001 0837443002 0772902010 0572998001 04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002156b708c7c6dd8afe31a743131d13b1e5dcbf2ce8c4...</td>\n",
       "      <td>0896152002 0897146002 0896152001 0896152003 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00281c683a8eb0942e22d88275ad756309895813e0648d...</td>\n",
       "      <td>0849591004 0870528003 0849591001 0870528002 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11734</th>\n",
       "      <td>fff2282977442e327b45d8c89afde25617d00124d0f999...</td>\n",
       "      <td>0919365008 0919786001 0919786002 0889496001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11735</th>\n",
       "      <td>fff2ef796ece5299d08227c49353043a92d61a3cdf4880...</td>\n",
       "      <td>0706016002 0797710001 0669091003 0851606001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11736</th>\n",
       "      <td>fff4d3a8b1f3b60af93e78c30a7cb4cf75edaf2590d3e5...</td>\n",
       "      <td>0614854005 0351484039 0448509018 0858147001 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11737</th>\n",
       "      <td>fffae8eb3a282d8c43c77dd2ca0621703b71e90904dfde...</td>\n",
       "      <td>0914441004 0652924004 0914441001 0706016001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11738</th>\n",
       "      <td>fffd0248a95c2e49fee876ff93598e2e20839e51b9b767...</td>\n",
       "      <td>0706016001 0372860001 0554450001 0759482001 04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11739 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             customer_id  \\\n",
       "0      0000757967448a6cb83efb3ea7a3fb9d418ac7adf2379d...   \n",
       "1      000fb6e772c5d0023892065e659963da90b1866035558e...   \n",
       "2      00125440be6cd148c3599b9c5a2d55f5838c1b0257d356...   \n",
       "3      002156b708c7c6dd8afe31a743131d13b1e5dcbf2ce8c4...   \n",
       "4      00281c683a8eb0942e22d88275ad756309895813e0648d...   \n",
       "...                                                  ...   \n",
       "11734  fff2282977442e327b45d8c89afde25617d00124d0f999...   \n",
       "11735  fff2ef796ece5299d08227c49353043a92d61a3cdf4880...   \n",
       "11736  fff4d3a8b1f3b60af93e78c30a7cb4cf75edaf2590d3e5...   \n",
       "11737  fffae8eb3a282d8c43c77dd2ca0621703b71e90904dfde...   \n",
       "11738  fffd0248a95c2e49fee876ff93598e2e20839e51b9b767...   \n",
       "\n",
       "                                              prediction  \n",
       "0      0706016001 0448509014 0715624001 0673677002 07...  \n",
       "1      0831684001 0740519002 0158340001 0915529003 09...  \n",
       "2      0892279001 0837443002 0772902010 0572998001 04...  \n",
       "3      0896152002 0897146002 0896152001 0896152003 08...  \n",
       "4      0849591004 0870528003 0849591001 0870528002 08...  \n",
       "...                                                  ...  \n",
       "11734  0919365008 0919786001 0919786002 0889496001 09...  \n",
       "11735  0706016002 0797710001 0669091003 0851606001 07...  \n",
       "11736  0614854005 0351484039 0448509018 0858147001 08...  \n",
       "11737  0914441004 0652924004 0914441001 0706016001 07...  \n",
       "11738  0706016001 0372860001 0554450001 0759482001 04...  \n",
       "\n",
       "[11739 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_final = format_outputs(df_valid_set)\n",
    "\n",
    "print(len(df_final.loc[df_final['prediction'].str.count(' ') != 11]))\n",
    "print(len(df_final.loc[df_final['prediction'].str[0]==' ']))\n",
    "print(len(df_final.loc[df_final['prediction'].str[-1]==' ']))\n",
    "\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST SCORE TRACKER: 9/9 - 9/15\n",
    "\n",
    "FULL SAMPLING\n",
    "- No association analysis:\n",
    "    - 1 XGB model: 0.06413008205486716\n",
    "    - Ensemble of XGB: ~0.066\n",
    "    - Repeat_0909_0915 + association + gen_pred_dict age: 0.0675903687192387\n",
    "    - Best possible: 0.13619358293437947\n",
    "    - Ranking model, full dataset, 1 LGBR: 0.07444375549285465\n",
    "    - Ranking model, only power users dataset + defaults for others, 1 LGBR: 0.07063352760425903 (WORSE)\n",
    "    - Ranking model, updated dataset + new hyperparameters, 20 LGBR: 0.07354104507494727\n",
    "\n",
    "5% SAMPLING\n",
    "\n",
    "- JUST BASELINE: 0.014222965110588631\n",
    "- No association analysis:\n",
    "    - 1 XGB model, 40 trees: 0.06021429816020317\n",
    "    - 30 Random Searches, 50-200 trees, early stopping, 2 wks training: 0.06279888629578777\n",
    "    - 50 Random Searches, 50-200 trees, early stopping, 8 wks training: 0.06310117709380794\n",
    "    \n",
    "- With ranking:\n",
    "    - 1 static model: 0.07120919702564296\n",
    "    - 20 static models: 0.07292343488960441\n",
    "    - 50 static models: 0.07342069763355963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07544701457349554"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_precision(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = df_final\n",
    "filename = 'rankerNewOptunaHP_RepeatNoThres_12assn_last30days_genpredage_neighbors12_7wktrain_v2.csv'\n",
    "\n",
    "output_df.to_csv('../Submissions/' + filename,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
