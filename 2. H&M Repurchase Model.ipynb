{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repurchase Model\n",
    "\n",
    "The purpose of this notebook is to **build a predictive model that identifies which articles are most likely to be repurchased by a customer, of their previous purchases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV,GroupKFold,RandomizedSearchCV\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data + fix data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ''\n",
    "\n",
    "# Read in articles data\n",
    "df_art = pd.read_csv('../Data/articles/articles'+sample+'.csv')\n",
    "df_cust = pd.read_csv('../Data/customers/customers'+sample+'.csv')\n",
    "df_trans = pd.read_csv('../Data/transactions_train/transactions_train'+sample+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix format of article IDs\n",
    "df_art['article_id'] = df_art['article_id'].astype(str).str.zfill(10)\n",
    "df_art['detail_desc'] = df_art['detail_desc'].astype(str)\n",
    "df_trans['article_id'] = df_trans['article_id'].astype(str).str.zfill(10)\n",
    "\n",
    "# # Fix datetime type\n",
    "df_trans['t_dat'] = pd.to_datetime(df_trans['t_dat'])\n",
    "\n",
    "# Build df_cust age brackets\n",
    "df_cust['Age_Bracket'] = pd.cut(df_cust['age'],[1,19,29,39,49,59,200],labels=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training dataset by removing the last 7 days of data\n",
    "\n",
    "test_start_date = '2020-09-09'\n",
    "test_end_date = '2020-09-15'\n",
    "\n",
    "df_trans_train = df_trans.loc[df_trans['t_dat'] < test_start_date,:].copy()\n",
    "df_trans_test = df_trans.loc[(df_trans['t_dat'] >= test_start_date)&(df_trans['t_dat'] <= test_end_date),:].copy()\n",
    "\n",
    "del df_trans\n",
    "del df_trans_train\n",
    "del df_art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in dataframe in submission format, returns MAP@12\n",
    "def calculate_precision(df_temp):\n",
    "    df = df_temp.copy()\n",
    "    df[list(range(1,13))] = pd.DataFrame(df.prediction.str.split(' ').tolist(),index=df.index)\n",
    "    del df['prediction']\n",
    "    df2 = pd.melt(df,id_vars = ['customer_id'])\n",
    "    df2.columns = ['customer_id','ranking','article_id']\n",
    "    \n",
    "    df_combined = pd.merge(df2,df_trans_test[['customer_id','article_id']].drop_duplicates(),how='inner')\n",
    "    df_combined['CumCount'] = df_combined.sort_values(['customer_id','ranking']).groupby('customer_id').cumcount() + 1\n",
    "    df_combined['Precision'] = df_combined['CumCount'] / df_combined['ranking']\n",
    "#     return df_combined\n",
    "    return df_combined['Precision'].sum()/(df_trans_test['customer_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build General Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pred_dict = pd.read_feather('../Datasets/gen_pred_dict.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training Pipeline\n",
    "\n",
    "This pipeline does the following - for each week we'd like to test:\n",
    "\n",
    "- Create the training set of all repeat datasets up until a given 7 day window, and the evaluation set of the 7 day window in question\n",
    "- Train 50 LightGB models, with previously established hyperparameters + each model with a different random sample of articles\n",
    "- Score each potential repurchase in a given week against each model, and average the results to find the overall score for an article\n",
    "- Identify all article/customer pairings with averaged scores >0.5, and output them as candidates for the full ranker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_sample = ''\n",
    "\n",
    "files = [\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0513_0519.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0520_0526.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0527_0602.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0603_0609.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0610_0616.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0617_0623.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0624_0630.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0701_0707.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0708_0714.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0715_0721.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0722_0728.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0729_0804.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0805_0811.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0812_0818.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0819_0825.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0826_0901.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0902_0908.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0909_0915.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0916_0922.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_FULL.feather'\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "sample = ''\n",
    "n_iterations = 50\n",
    "no_multiplier = 3\n",
    "\n",
    "strt = dt.datetime.now()\n",
    "\n",
    "for test_set_ind in range(4,20):\n",
    "    print('Begin',files[test_set_ind],dt.datetime.now()-strt)\n",
    "    print('Create Training Set',dt.datetime.now()-strt)\n",
    "    df_train_set = pd.DataFrame()\n",
    "    \n",
    "    # Create the training set, randomly sample + concatenate all files prior to the test week\n",
    "    for i,f in enumerate(files):\n",
    "        if i == test_set_ind:\n",
    "            break\n",
    "        df_temp = pd.read_feather(f)\n",
    "        df_yes = df_temp.loc[df_temp['Response'] == 1]\n",
    "        df_train_set = pd.concat([df_train_set,df_yes,df_temp.loc[df_temp['Response']==0].sample(frac=1/(test_set_ind-1),random_state=i)])\n",
    "        del df_temp\n",
    "        del df_yes\n",
    "    df_train_set = df_train_set.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Format the training set - identify all yes instances of repurchase\n",
    "    print('Build Datasets',dt.datetime.now()-strt)\n",
    "    df_prep = df_train_set.loc[:,[i for i in df_train_set.columns if i not in \\\n",
    "                                ['customer_id','article_id','t_dat']]].copy().sample(frac=1,random_state=11)\n",
    "    if 'LastMonthPopularity' in df_prep.columns:\n",
    "        del df_prep['LastMonthPopularity']\n",
    "    yeses = df_prep.loc[df_prep['Response']==1].copy()\n",
    "    del df_train_set\n",
    "    \n",
    "    \n",
    "    print('Train Models',dt.datetime.now()-strt,len(yeses))\n",
    "\n",
    "    models = []\n",
    "    model_n = len(yeses)*no_multiplier\n",
    "\n",
    "    for rs in range(n_iterations):\n",
    "        if rs % 10 == 0:\n",
    "            print(rs)\n",
    "        # Create modeling dataset, pull yes instances + 10K no instances\n",
    "        others = df_prep.loc[df_prep['Response']==0].copy().sample(n=model_n,random_state=rs)\n",
    "        ys = yeses.sample(n=len(others),replace=True,random_state=rs)\n",
    "\n",
    "        train = pd.concat([ys,others]).sample(frac=1,random_state=rs)\n",
    "        trainX = train.loc[:,[i for i in train.columns if i != 'Response']]\n",
    "        trainy = train['Response']\n",
    "\n",
    "        # 5% sample dataset\n",
    "#         xgb_clf = xgb.XGBClassifier(random_state=123,use_label_encoder=False,\\\n",
    "#                                    min_child_weight=5,colsample_bytree=.8,max_depth=4,verbosity=0,\\\n",
    "#                                    reg_alpha=.1,reg_lambda=.1,learning_rate=.1)\n",
    "\n",
    "        # Full dataset\n",
    "        xgb_clf = xgb.XGBClassifier(random_state=123,use_label_encoder=False,n_estimators=250,\\\n",
    "                                   min_child_weight=5,colsample_bytree=.8,max_depth=4,verbosity=0,\\\n",
    "                                   reg_alpha=.1,reg_lambda=.1,learning_rate=.14)\n",
    "\n",
    "        xgb_clf.fit(trainX,trainy)\n",
    "\n",
    "        models.append(xgb_clf)\n",
    "        del others\n",
    "        del ys\n",
    "        del train\n",
    "        del trainX\n",
    "        del trainy\n",
    "\n",
    "    del df_prep\n",
    "    del yeses\n",
    "    \n",
    "    \n",
    "    print('Score test set',dt.datetime.now()-strt)\n",
    "    #READ IN TEST SET\n",
    "    df_test_set = pd.read_feather(files[test_set_ind])\n",
    "    if 'LastMonthPopularity' in df_test_set.columns:\n",
    "        del df_test_set['LastMonthPopularity']\n",
    "\n",
    "    # Create test data\n",
    "    df_testX = df_test_set[[i for i in df_test_set.columns if i not in ['Response','customer_id','article_id','t_dat']]].copy()\n",
    "\n",
    "    df_ensemble = df_test_set[['customer_id','article_id','t_dat']].copy()\n",
    "    df_ensemble['sum_prob'] = 0\n",
    "\n",
    "    del df_test_set\n",
    "    \n",
    "    # Sum the predictions of all models generated, and then average them\n",
    "    for i,m in enumerate(models):\n",
    "        df_ensemble['sum_prob'] += m.predict_proba(df_testX)[:,1]\n",
    "    del df_testX\n",
    "\n",
    "    df_ensemble['predict_prob'] = df_ensemble['sum_prob'] / len(models)\n",
    "    df_ensemble['rank'] = df_ensemble.groupby('customer_id')['predict_prob'].rank('first',ascending=False)\n",
    "    \n",
    "    # Write the output!\n",
    "    if 'FULL' in files[test_set_ind]:\n",
    "        date_part = 'FULL'\n",
    "    else:\n",
    "        date_part = files[test_set_ind][-17:-8]\n",
    "    \n",
    "    df_ensemble[['customer_id','article_id','predict_prob','rank']].to_feather('../Datasets/Outputs'+sample+\\\n",
    "                                                                               '/RepeatFULL_'+date_part+'.feather')\n",
    "    del df_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive - Individual component tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_sample = ''\n",
    "\n",
    "test_set_ind = 17\n",
    "\n",
    "files = [\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0513_0519.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0520_0526.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0527_0602.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0603_0609.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0610_0616.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0617_0623.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0624_0630.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0701_0707.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0708_0714.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0715_0721.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0722_0728.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0729_0804.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0805_0811.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0812_0818.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0819_0825.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0826_0901.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0902_0908.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0909_0915.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_0916_0922.feather',\\\n",
    "         '../Datasets/Repeat'+pct_sample+'/Repurchase_FULL.feather'\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE ALL TRAINING SETS\n",
    "\n",
    "df_train_set = pd.DataFrame()\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    if i == test_set_ind:\n",
    "        break\n",
    "    df_temp = pd.read_feather(f)\n",
    "    print(f,df_temp['t_dat'].max())\n",
    "    df_yes = df_temp.loc[df_temp['Response'] == 1]\n",
    "    df_train_set = pd.concat([df_train_set,df_yes,df_temp.loc[df_temp['Response']==0].sample(frac=1/(test_set_ind-1),random_state=i)])\n",
    "    del df_temp\n",
    "    del df_yes\n",
    "\n",
    "df_train_set = df_train_set.reset_index(drop=True)\n",
    "print(len(df_train_set))\n",
    "\n",
    "df_prep = df_train_set.loc[:,[i for i in df_train_set.columns if i not in \\\n",
    "                            ['customer_id','article_id','t_dat']]].copy().sample(frac=1,random_state=11)\n",
    "del df_prep['LastMonthPopularity']\n",
    "\n",
    "yeses = df_prep.loc[df_prep['Response']==1].copy()\n",
    "\n",
    "del df_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTUNA\n",
    "\n",
    "I used Optuna to find the best possible hyperparameters for my LightGB model. The steps I used were:\n",
    "\n",
    "- Generate 6 random samplings of the training set to be averaged\n",
    "- For each one, tune a LightGB classification model using the provided hyperparameters, and **score the model based on recall**\n",
    "    - e.g. what percent of actual repurchases scored >50% likelihood to repurchase in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training sets for our Optuna models\n",
    "\n",
    "trains = []\n",
    "num_train_sets = 6\n",
    "\n",
    "for it in range(num_train_sets):\n",
    "    print(it)\n",
    "    others = df_prep.loc[df_prep['Response']==0].copy().sample(n=300000,random_state=it)\n",
    "    ys = yeses.sample(n=len(others),replace=True,random_state=it)\n",
    "    \n",
    "    train = pd.concat([ys,others]).sample(frac=1,random_state=it).reset_index(drop=True)\n",
    "    trains.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create our test set to be scored in the Optuna model\n",
    "\n",
    "#READ IN TEST SET\n",
    "df_test_set = pd.read_feather(files[test_set_ind])\n",
    "print(files[test_set_ind],len(df_test_set))\n",
    "if 'LastMonthPopularity' in df_test_set.columns:\n",
    "    del df_test_set['LastMonthPopularity']\n",
    "\n",
    "np.random.seed(0)\n",
    "rand_cust = np.random.choice(df_cust['customer_id'],size=600000,replace=False)    \n",
    "\n",
    "# Create test output\n",
    "testDF = df_test_set.loc[df_test_set['customer_id'].isin(rand_cust),['customer_id','article_id','Response']].copy()\n",
    "\n",
    "# Create test data\n",
    "df_testX = df_test_set.loc[df_test_set['customer_id'].isin(rand_cust),\\\n",
    "        [i for i in df_test_set.columns if i not in ['Response','customer_id','article_id','t_dat']]].copy()\n",
    "del df_test_set\n",
    "\n",
    "print(len(testDF))\n",
    "\n",
    "num_repurchases = testDF['Response'].sum()\n",
    "print(num_repurchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_LGBM(trial):\n",
    "    global testDF\n",
    "    param = {\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type',['gbdt','goss']),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', .0001, 100),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', .0001, 100),\n",
    "        'min_split_gain': trial.suggest_loguniform('min_split_gain',1e-4,15),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.8,0.9,1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.8,0.9,1.0]),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', .01,.4),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',100,400,step=10),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 5),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 500),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 30)\n",
    "    }\n",
    "    \n",
    "    strt = dt.datetime.now()\n",
    "\n",
    "    recall = 0\n",
    "    size_of_set = 0\n",
    "    for i,t in enumerate(trains):\n",
    "        yt = t['Response']\n",
    "        Xt = t.drop('Response',axis=1)\n",
    "        clf = lgbm.LGBMClassifier(random_state=123,**param)\n",
    "        clf.fit(Xt,yt,callbacks=[lgbm.log_evaluation(period=0)])\n",
    "\n",
    "        testDF['Pred'] = clf.predict(df_testX)\n",
    "        testScore = testDF.loc[testDF['Pred'] >= 0.5].copy()\n",
    "        \n",
    "        recall += testScore['Response'].sum()\n",
    "        size_of_set += len(testScore)\n",
    "\n",
    "    print(recall/len(trains),size_of_set/len(trains))\n",
    "    return (recall / len(trains)) / (size_of_set / len(trains))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_LGBM, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = study.trials\n",
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter down to top results per person, and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_final_results(df):\n",
    "    N = 12\n",
    "    # Pivot the results, and concatenate together into the final format\n",
    "    df_pivoted = pd.pivot(df,index='customer_id',columns='rank',values='article_id').fillna('')\n",
    "    df_pivoted.columns = list(range(1,N+1))\n",
    "    df_pivoted['pred_model_list'] = df_pivoted[list(range(1,N+1))].apply(\\\n",
    "                                    lambda row: ' '.join(row.values.astype(str)), axis=1).str.strip(' ')\n",
    "    df_pivoted = df_pivoted[['pred_model_list']].copy().reset_index()\n",
    "    \n",
    "    # Join to the full list of customers and identify how many predictions are remaining for each\n",
    "    df_final = df_cust[['customer_id']].copy()\n",
    "    df_final = pd.merge(df_final,df_pivoted,how='left',on='customer_id')\n",
    "    df_final['pred_model_list'] = df_final['pred_model_list'].fillna('').str.split(' ')\n",
    "#     df_final['assn_list'] = build_assn_list()\n",
    "    return df_final\n",
    "\n",
    "df_final = format_final_results(df_valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association analysis - filter down to articles sold in the 2 weeks prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each customer, take the top 3 associations (3 from #1, 2 from #1 and 1 from #2, or 1 from #1,#2,#3)\n",
    "\n",
    "def build_assn_list():\n",
    "    \n",
    "    df_artdict = pd.read_csv('../Datasets/association_v2.csv')\n",
    "    art_dict2 = {}\n",
    "    for x in df_artdict.itertuples():\n",
    "        art_dict2[str(x[1]).zfill(10)] = [str(j).zfill(10) for j in list(x[2:])]\n",
    "    \n",
    "    N = 3\n",
    "\n",
    "    assn_list = []\n",
    "    for x in tqdm(df_final.itertuples()):\n",
    "        cust_id = x[1]\n",
    "        pred_model_list = x[2]\n",
    "        if len(pred_model_list) > 0:\n",
    "            # Check if the predictions we've made show up in association dictionary\n",
    "            matches = [i for i in pred_model_list if i in art_dict2]\n",
    "\n",
    "            # If we have no matches, return nothing\n",
    "            if len(matches) == 0:\n",
    "                l = []\n",
    "\n",
    "            # If we have 1 match, return the top 2 associations for that match\n",
    "            elif len(matches) == 1:\n",
    "                available = [i for i in art_dict2[matches[0]] if i not in pred_model_list]\n",
    "                l = available[:N]\n",
    "\n",
    "            # If we have 2+ matches return the top association for the top 2 articles that we match\n",
    "            elif len(matches) == 2:\n",
    "                available1 = [i for i in art_dict2[matches[0]] if i not in pred_model_list]\n",
    "                available2 = [i for i in art_dict2[matches[1]] if i not in pred_model_list and i not in available1[:2]]\n",
    "                l = available1[:2] + [available2[0]]\n",
    "                if len(l) < 3:\n",
    "                    print(l)\n",
    "                    print(hello)\n",
    "            else:\n",
    "                available1 = [i for i in art_dict2[matches[0]] if i not in pred_model_list]\n",
    "                available2 = [i for i in art_dict2[matches[1]] if i not in pred_model_list and i != available1[0]]\n",
    "                available3 = [i for i in art_dict2[matches[2]] if i not in pred_model_list and i != available1[0] \\\n",
    "                                                                         and i != available2[0]]\n",
    "                l = available1[:1] + available2[:1] + available3[:1]\n",
    "                if len(l) < 3:\n",
    "                    print(l)\n",
    "                    print(hello)\n",
    "\n",
    "\n",
    "        assn_list.append(l)\n",
    "    return assn_list\n",
    "\n",
    "\n",
    "df_final['Associations'] = build_assn_list()\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association Analysis - find the number of customers who bought each article alongside target article\n",
    "\n",
    "## READ IN ASSOCIATION DICTIONARY TO BYPASS THE LONG STEP\n",
    "\n",
    "# df_artdict = pd.read_csv('../Datasets/association_v2.csv')\n",
    "# art_dict2 = {}\n",
    "# for x in df_artdict.itertuples():\n",
    "#     art_dict2[str(x[1]).zfill(10)] = [str(j).zfill(10) for j in list(x[2:])]\n",
    "\n",
    "# CREATE NEW DATASET (NOTE: THIS TAKES 1.1 HOURS TO RUN FOR 1500 ARTICLES)\n",
    "# Truncate dataset to articles sold in the last 2 weeks, for scalability\n",
    "\n",
    "# sold_last_week = df_trans.loc[df_trans['t_dat'] >= '2020-08-01','article_id'].unique()\n",
    "# df_trans_train2 = df_trans.loc[df_trans['article_id'].isin(sold_last_week)].copy()\n",
    "# top_articles = df_trans_train2['article_id'].value_counts()[:30000].index.tolist()\n",
    "# ta = [i for i in top_articles if i not in art_dict2]\n",
    "\n",
    "# for art_id in tqdm(ta):\n",
    "#     if art_id in art_dict2:\n",
    "#         continue\n",
    "#     buyers = df_trans_train2.loc[df_trans_train2['article_id']==art_id,'customer_id'].unique()\n",
    "#     others = df_trans_train2.loc[(df_trans_train2['customer_id'].isin(buyers))&(df_trans_train2['article_id'] != art_id),\\\n",
    "#                                'article_id'].value_counts()[:12]\n",
    "#     art_dict2[art_id] = list(others.index)\n",
    "\n",
    "## CONVERT ASSOCIATION DICTIONARY INTO A CSV SO WE DON'T NEED TO KEEP REPEATING THIS LONG PROCESS\n",
    "\n",
    "# df_artdict = pd.DataFrame(art_dict2).T.reset_index().rename(columns={'index':'article_id'})\n",
    "# df_artdict.to_csv('../Data/association_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill remainder from general_pred, and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST SCORE TRACKER: 9/9 - 9/15\n",
    "\n",
    "FULL SAMPLING\n",
    "- No association analysis:\n",
    "    - 1 XGB model: 0.06413008205486716\n",
    "    - Ensemble of XGB: ~0.066\n",
    "    - Best possible: 0.13619358293437947\n",
    "\n",
    "5% SAMPLING\n",
    "\n",
    "- JUST BASELINE: 0.014222965110588631\n",
    "- No association analysis:\n",
    "    - 1 XGB model, 40 trees: 0.06021429816020317\n",
    "    - 30 Random Searches, 50-200 trees, early stopping, 2 wks training: 0.06279888629578777\n",
    "    - 50 Random Searches, 50-200 trees, early stopping, 8 wks training: 0.06310117709380794\n",
    "    \n",
    "- Pre-changes: 1 model,  .0626 without association, .0657 with association\n",
    "- Post-changes: 1 model, .0644 without association, .0674 with association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our final score dataframe\n",
    "df_score = df_final[['customer_id']].copy()\n",
    "\n",
    "# Read in our cold start general prediction based on age bracket\n",
    "df_final2 = pd.merge(df_final,df_cust[['customer_id','Age_Bracket']],how='left',on='customer_id').fillna(2)\n",
    "df_final2 = pd.merge(df_final2,gen_pred_dict,on='Age_Bracket').sort_values(by='customer_id')\n",
    "\n",
    "del df_final2['Age_Bracket']\n",
    "\n",
    "# Build the final prediction:\n",
    "# First - concatenate the list of repurchases\n",
    "# Then - concatenate any purchase associations\n",
    "# Finally - Append the cold start general predictions for anyone who still has fewer than 12 in their list\n",
    "\n",
    "final_prediction = []\n",
    "for x in tqdm(df_final2.itertuples()):\n",
    "    ans = list(x[2]) + list(x[3]) + [i for i in list(x[4]) if i not in list(x[2]) and i not in list(x[3])]\n",
    "    ans = [i for i in ans if i != ''][:12]\n",
    "    if len(ans) > len(set(ans)) or len(ans) != 12:\n",
    "        print(ans)\n",
    "        break\n",
    "    final_prediction.append(' '.join(ans))\n",
    "df_score['prediction'] = final_prediction\n",
    "\n",
    "# Calculate the MAP@12!\n",
    "calculate_precision(df_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
