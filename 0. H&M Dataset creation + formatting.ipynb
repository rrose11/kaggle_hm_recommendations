{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation + formatting\n",
    "\n",
    "The purpose of this notebook is to **run some initial data preparation prior to the modeling notebooks in this folder**. \n",
    "\n",
    "Some of the data preparation steps in this notebook include:\n",
    "- Creation of the 5% sample and 10% sample datasets\n",
    "- Creation of the tf-idf PCA columns based off the article descriptions\n",
    "- Creation of the association analysis dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from scipy import sparse \n",
    "from pandas.api.types import CategoricalDtype \n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV,GroupKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk import *\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data + fix data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '_05'\n",
    "\n",
    "# Read in articles data\n",
    "df_art = pd.read_csv('../Data/articles/articles'+sample+'.csv')\n",
    "df_cust = pd.read_csv('../Data/customers/customers'+sample+'.csv')\n",
    "df_trans = pd.read_csv('../Data/transactions_train/transactions_train'+sample+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix format of article IDs\n",
    "df_art['article_id'] = df_art['article_id'].astype(str).str.zfill(10)\n",
    "df_art['detail_desc'] = df_art['detail_desc'].astype(str)\n",
    "df_trans['article_id'] = df_trans['article_id'].astype(str).str.zfill(10)\n",
    "\n",
    "# Fix datetime type\n",
    "df_trans['t_dat'] = pd.to_datetime(df_trans['t_dat'])\n",
    "\n",
    "# Build df_cust age brackets\n",
    "df_cust['Age_Bracket'] = pd.cut(df_cust['age'],[1,19,29,39,49,59,200],labels=[1,2,3,4,5,6]).fillna(2)\n",
    "\n",
    "# Update the color column for df_art\n",
    "df_art['color'] = np.where(df_art['perceived_colour_master_name'].isin(['Blue','Turquoise','Bluish Green']),'Blue',\\\n",
    "                  np.where(df_art['perceived_colour_master_name'].isin(['Green','Yellowish Green','Khaki green']),'Green',\\\n",
    "                  np.where(df_art['perceived_colour_master_name'].isin(['Brown','Beige','Mole']),'Brown',\\\n",
    "                  np.where(df_art['perceived_colour_master_name'].isin(['Grey','Metal']),'Grey',\\\n",
    "                           df_art['perceived_colour_master_name']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify age + gender category of an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art['Age_Category'] = np.where(df_art['index_group_name']=='Baby/Children','Kids',\\\n",
    "                                 np.where(df_art['index_group_name']=='Divided','YA','Adult'))\n",
    "\n",
    "femaleproducts = ['Dress','Leggings/Tights','Bag','Skirt','Bra','Hair/alice band','Blouse','Earring','Bikini top',\\\n",
    "                 'Hair string','Necklace','Bodysuit','Ballerinas','Pumps','Underwear Tights','Bracelet','Ring','Wedge']\n",
    "\n",
    "fDepts = ['Ladies','Girls']\n",
    "mDepts = ['Men','Boys']\n",
    "\n",
    "female_depts = [i for i in df_art['department_name'].unique() if any([x in i for x in fDepts])]\n",
    "male_depts = [i for i in df_art['department_name'].unique() if any([x in i for x in mDepts])]\n",
    "\n",
    "female_sect = [i for i in df_art['section_name'].unique() if any([x in i for x in fDepts])]\n",
    "male_sect = [i for i in df_art['section_name'].unique() if any([x in i for x in mDepts])]\n",
    "\n",
    "female_desc = [i for i in df_art['detail_desc'].unique() if any([' ' + x.lower() + ' ' in i for x in fDepts]) or\\\n",
    "                                               any([' ' + x.lower() + ' ' in i for x in femaleproducts])]\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['index_name'].isin(['Ladieswear','Ladies Accessories','Lingeries/Tights']),\\\n",
    "                                     'F',np.where(df_art['index_name'].isin(['Menswear']),'M','U'))\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['Gender_Category'] != 'U',df_art['Gender_Category'],\\\n",
    "                                np.where(df_art['garment_group_name'].isin(['Dresses Ladies','Blouses','Skirts']),'F','U'))\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['Gender_Category'] != 'U',df_art['Gender_Category'],\\\n",
    "                                np.where(df_art['product_type_name'].isin(femaleproducts),'F','U'))\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['Gender_Category'] != 'U',df_art['Gender_Category'],\\\n",
    "                                np.where(df_art['department_name'].isin(male_depts),'M',\\\n",
    "                                np.where(df_art['department_name'].isin(female_depts),'F','U')))\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['Gender_Category'] != 'U',df_art['Gender_Category'],\\\n",
    "                                np.where(df_art['section_name'].isin(male_sect),'M',\\\n",
    "                                np.where(df_art['section_name'].isin(female_sect),'F','U')))\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['Gender_Category'] != 'U',df_art['Gender_Category'],\\\n",
    "                                np.where(df_art['detail_desc'].isin(female_desc),'F','U'))\n",
    "\n",
    "df_art['Gender_Category'] = np.where(df_art['Gender_Category'] != 'U',df_art['Gender_Category'],\\\n",
    "                                np.where(df_art['index_group_name']!='Baby/Children','U',\\\n",
    "                                np.where(df_art['color']=='Blue','M',np.where(df_art['color']=='Pink','F','U'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write article csv with updated columns for future use\n",
    "df_art.to_csv('../Data/articles/articles'+sample+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article description Tf-idf + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = []\n",
    "bad_words = list(set(bad_words + [i for i in feature_names if any([j in i for j in ['0','1','2','3','4','5','6','7','8','9']])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = df_art['detail_desc']\n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(bad_words)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=my_stop_words)\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = vectors.todense()\n",
    "list_dense = matrix.tolist()\n",
    "df = pd.DataFrame(list_dense,columns=feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.sum().sort_values()\n",
    "df2 = df[x[x > 500].index]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = 10\n",
    "\n",
    "transformer = PCA(n_components=components,random_state=0)\n",
    "transformer.fit(df2)\n",
    "df3 = pd.DataFrame(transformer.fit_transform(df2),columns = ['PCA'+str(i) for i in range(1,components+1)],index=df_art['article_id']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('../Datasets/PCA_Vectorizer.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD SAMPLE DATASET\n",
    "\n",
    "Build a 5% and 10% dataset based on active customers (defined as customers with 5+ purchases and a most recent purchase in the last 365 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 70K valid customers (purchase in last year and at least 5 articles purchased)\n",
    "df_num_purchases = df_trans.groupby('customer_id').agg({'t_dat':['nunique','max'],'article_id':'count'})\n",
    "df_num_purchases.columns = ['NumShoppingDays','LastShoppingDay','NumPurchases']\n",
    "df_num_purchases = df_num_purchases.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_customers = df_num_purchases.loc[(df_num_purchases['LastShoppingDay'] >= '2019-09-22') & \\\n",
    "                                      (df_num_purchases['NumPurchases'] >= 5),['customer_id']]\n",
    "valid_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust_sample = valid_customers.sample(len(df_cust)*(percentage/100), replace=False)\n",
    "df_trans_sample = df_trans.loc[df_trans['customer_id'].isin(df_cust_sample['customer_id'])]\n",
    "df_cust_final = df_cust.loc[df_cust['customer_id'].isin(df_cust_sample['customer_id'])]\n",
    "df_art_sample = df_art.loc[df_art['article_id'].isin(df_trans_sample['article_id'])]\n",
    "df_trans_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art_sample.to_csv('../Data/articles/articles_'+str(percentage)+'.csv',index=False)\n",
    "df_trans_sample.to_csv('../Data/transactions_train/transactions_train_'+str(percentage)+'.csv',index=False)\n",
    "df_cust_final.to_csv('../Data/customers/customers_'+str(percentage)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association analysis - filter down to articles sold in the 2 weeks prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate dataset to articles sold in the last 2 weeks, for scalability\n",
    "sold_last_week = df_trans.loc[df_trans['t_dat'] >= '2020-09-07','article_id'].unique()\n",
    "df_trans_train2 = df_trans.loc[df_trans['article_id'].isin(sold_last_week)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association Analysis - find the number of customers who bought each article alongside target article\n",
    "# NOTE: THIS TAKES 1.1 HOURS TO RUN FOR 1500 ARTICLES\n",
    "\n",
    "top_articles = df_trans_train2['article_id'].value_counts()[:15000]\n",
    "\n",
    "# art_dict = {}\n",
    "\n",
    "for art_id in tqdm(top_articles.index):\n",
    "    buyers = df_trans_train2.loc[df_trans_train2['article_id']==art_id,'customer_id'].unique()\n",
    "    others = df_trans_train2.loc[(df_trans_train2['customer_id'].isin(buyers))&(df_trans_train2['article_id'] != art_id),\\\n",
    "                               'article_id'].value_counts()[:12]\n",
    "    art_dict[art_id] = others\n",
    "\n",
    "art_dict2 = {i:list(art_dict[i].index) for i in art_dict}\n",
    "\n",
    "\n",
    "\n",
    "## CONVERT ASSOCIATION DICTIONARY INTO A CSV SO WE DON'T NEED TO KEEP REPEATING THIS LONG PROCESS\n",
    "\n",
    "df_artdict = pd.DataFrame(art_dict2).T.reset_index().rename(columns={'index':'article_id'})\n",
    "df_artdict.to_csv('../Data/association_v2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
